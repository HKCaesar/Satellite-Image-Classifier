{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le-Net 1 based architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with 41X41 (I) after first convolution (9x9)we have 33X33 (L1). The next pooling layer reduces dimension with 3 to an output image of 11X11 with 4x4 pooling kernels (L2). Then we apply different types of convolution 4x4 kernels on the L2 layer resulting in 8x8 (L3) . Then followed by pooling 2X2 resulting in 4x4 output map (L4). So we have 16 connection for each element in layer L4 (which depend on the amount of different Covolutions in L3) \n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "f(x)=\\frac{1}{1+e^{-x}} \\\\\n",
    "F_{k}= f( \\sum_{i} \\mathbf{W^{k}_{i} \\cdot y_{i}}-b_{k})\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "E=\\sum_{k} \\frac{1}{2}|t_k-F_{k}|^{2} \\\\\n",
    "\\Delta W_{ij}= - \\eta \\frac{dE}{d W_{ij}}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta W_{ij}= \\sum_{k} - \\eta \\frac{dE}{d F_{k}} \\frac{dF_{k}}{dx_{k}} \\frac{dx_{k}}{dW_{ij}}=\\sum_{k} \\eta (t_{k}-F_{k})\\frac{e^{-x_{k}}}{(1+e^{-x_{k}})^{2}} \\frac{dx_{k}}{dW_{ij}} \\\\\n",
    "= \\eta (t_{k}-F_{k})\\frac{e^{-x_{k}}}{(1+e^{-x_{k}})^{2}} y_{ij}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\Delta b_{k}= - \\eta \\frac{dE}{d F_{k}} \\frac{dF_{k}}{dx_{k}} \\frac{dx_{k}}{b_{k}}=\\eta (t_{k}-F_{k})\\frac{e^{-x_{k}}}{(1+e^{-x_{k}})^{2}} \\cdot-1\n",
    "\\end{equation}\n",
    "\n",
    "Since $\\frac{e^{-x_{k}}}{(1+e^{-x_{k}})^{2}}$ is always positive we can neglect this term in our programme\n",
    "\n",
    "\\begin{equation}\n",
    "x_{k}=\\sum_{ij} W^{k}[i,j] \\; y^{4rb}[i,j] - b_{k}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "y^{4rb}[i,j]= \\sum_{u,v} W^{3rb}[u,v] \\; y^{3rb} [2i+u,2j+v]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "y^{3rb} [2i+u,2j+v]= f\\left (x^{3rb}[2i+u,2j+v] \\right)\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "x^{3rb}[2i+u,2j+v]=\\sum_{nm} W^{2rb}[n,m] \\; y^{2rb}[n+(2i+u),m+(2j+v)] -b^{3rb}[2i+u,2j+v]\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\Delta W^{2rb}[n,m] =\\sum_{k} - \\eta  \\frac{dE}{dF_{k}} \n",
    "\\frac{dF_{k}}{dx_{k}} \n",
    "\\sum_{ij} \\frac{dx_{k}}{dy^{4rb}[i,j]} \n",
    " \\sum_{uv}\\frac{dy^{4rb}[i,j]}{d y^{3rb} [2i+u,2j+v]} \n",
    "\\frac{d y^{3rb} [2i+u,2j+v]}{d x^{3rb}[2i+u,2j+v]}\n",
    "\\sum_{nm}\\frac{d x^{3rb}[2i+u,2j+v]}{d W^{2rb}[n,m]}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\Delta b^{3rb}[2i+u,2j+v] =\\sum_{k} - \\eta  \\frac{dE}{dF_{k}} \n",
    "\\frac{dF_{k}}{dx_{k}} \n",
    "\\sum_{ij} \\frac{dx_{k}}{dy^{4rb}[i,j]} \n",
    " \\sum_{uv}\\frac{dy^{4rb}[i,j]}{d y^{3rb} [2i+u,2j+v]} \n",
    "\\frac{d y^{3rb} [2i+u,2j+v]}{d x^{3rb}[2i+u,2j+v]}\n",
    "\\frac{d x^{3rb}[2i+u,2j+v]}{d b^{3rb}[2i+u,2j+v]}\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dx_{k}}{dy^{4rb}[i,j]} = W^{4rbk}[i,j]\\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "    \\frac{dy^{4rb}[i,j]}{d y^{3rb} [2i+u,2j+v]} = W^{3rb}[u,v] \\\\\n",
    " \\end{equation}\n",
    " \n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d y^{3rb} [2i+u,2j+v]}{d x^{3rb}[2i+u,2j+v]}=\\frac{e^{-x^{3rb}[2i+u,2j+v]}}{(1+e^{-x^{3rb}[2i+u,2j+v]})^2}\n",
    "\\end{equation}\n",
    "This term is first not included since it is always positive. If the training will not converge it might be possible to include this term\n",
    "\n",
    " \\begin{equation}\n",
    "    \\frac{d y^{3rb} [2i+u,2j+v]}{d W^{2rb}[n,m]}= y^{2rb} [n+(2i+u),m+(2j+v)] \\\\\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\frac{d x^{3rb}[2i+u,2j+v]}{d b^{3rb}[2i+u,2j+v]}=-1\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as lin\n",
    "import scipy.signal as sig\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.cm as cm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########### Load Input ############################################################################################################################\n",
    "# In this script I used the brightness to determine structures, instead of one RGB color:\n",
    "# this is determined by: 0.2126*R + 0.7152*G + 0.0722*B\n",
    "# Source: https://en.wikipedia.org/wiki/Relative_luminance\n",
    "\n",
    "patchSize=41 # patchsize this must be 48 since our network can only handle this value\n",
    "\n",
    "# Open forest\n",
    "Amount_data= len(glob.glob('Forest/F*'))\n",
    "dataPatchedF=[]\n",
    "dataF_RGB=[]\n",
    "\n",
    "for k in range (0, Amount_data):\n",
    "    name=\"Forest/F%d.png\" % (k+1)\n",
    "    img = Image.open(name)\n",
    "    data=img.convert('RGB')\n",
    "    data= np.asarray( data, dtype=\"int32\" )\n",
    "    data=0.2126*data[:,:,0]+0.7152*data[:,:,1]+0.0722*data[:,:,2]\n",
    "    data2=img.convert('RGB')\n",
    "    data2= np.asarray( data2, dtype=\"int32\" )\n",
    "\n",
    "    Yamount=data.shape[0]/patchSize # Counts how many times the windowsize fits in the picture\n",
    "    Xamount=data.shape[1]/patchSize # Counts how many times the windowsize fits in the picture\n",
    "    dataPatchedF.append(np.array([[data[j*patchSize:(j+1)*patchSize,i*patchSize:(i+1)*patchSize] for i in range(0,Xamount)] for j in range(0,Yamount)]))\n",
    "    for m in range(0,3):\n",
    "        dataF_RGB.append(np.array([[data2[j*patchSize:(j+1)*patchSize,i*patchSize:(i+1)*patchSize,m] for i in range(0,Xamount)] for j in range(0,Yamount)]))\n",
    "\n",
    "# Open city\n",
    "Amount_data= len(glob.glob('City/C*'))\n",
    "dataPatchedC=[]\n",
    "dataC_RGB=[]\n",
    "\n",
    "for k in range (0, Amount_data):\n",
    "    name=\"City/C%d.png\" % (k+1)\n",
    "    img = Image.open(name)\n",
    "    data=img.convert('RGB')\n",
    "    data = np.asarray( data, dtype=\"int32\" )\n",
    "    data=0.2126*data[:,:,0]+0.7152*data[:,:,1]+0.0722*data[:,:,2]\n",
    "    data2=img.convert('RGB')\n",
    "    data2= np.asarray( data2, dtype=\"int32\" )\n",
    "\n",
    "    Yamount=data.shape[0]/patchSize # Counts how many times the windowsize fits in the picture\n",
    "    Xamount=data.shape[1]/patchSize # Counts how many times the windowsize fits in the picture    \n",
    "    dataPatchedC.append(np.array([[data[j*patchSize:(j+1)*patchSize,i*patchSize:(i+1)*patchSize] for i in range(0,Xamount)] for j in range(0,Yamount)]))\n",
    "    for m in range(0,3):\n",
    "        dataC_RGB.append(np.array([[data2[j*patchSize:(j+1)*patchSize,i*patchSize:(i+1)*patchSize,m] for i in range(0,Xamount)] for j in range(0,Yamount)]))\n",
    "\n",
    "# Open water\n",
    "dataPatchedW=[]\n",
    "Amount_data= len(glob.glob('Water/W*'))\n",
    "dataW_RGB=[]\n",
    "\n",
    "for k in range (0, Amount_data): \n",
    "    name=\"Water/W%d.png\" % (k+1)\n",
    "    img = Image.open(name)\n",
    "    data=img.convert('RGB')\n",
    "    data = np.asarray( data, dtype=\"int32\" )\n",
    "    data=0.2126*data[:,:,0]+0.7152*data[:,:,1]+0.0722*data[:,:,2]   \n",
    "    Yamount=data.shape[0]/patchSize # Counts how many times the windowsize fits in the picture\n",
    "    Xamount=data.shape[1]/patchSize # Counts how many times the windowsize fits in the picture\n",
    "    dataPatchedW.append(np.array([[data[j*patchSize:(j+1)*patchSize,i*patchSize:(i+1)*patchSize] for i in range(0,Xamount)] for j in range(0,Yamount)])) \n",
    "    #for m in range(0,3):\n",
    "        # dataW_t=np.array([[data2[j*patchSize:(j+1)*patchSize,i*patchSize:(i+1)*patchSize,m] for i in range(0,Xamount)] for j in range(0,Yamount)]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "A=np.array([[data2[j*patchSize:(j+1)*patchSize,i*patchSize:(i+1)*patchSize,m] for i in range(0,Xamount)] for j in range(0,Yamount)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 32, 41, 41)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########### Functions ############################################################################################################################\n",
    "\n",
    "# Define Activitation functions, pooling and convolution functions (the rules)\n",
    "\n",
    "def Sigmoid(x): \n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def Sigmoid_dx(x):\n",
    "    return np.exp(-x)/((1+np.exp(-x))**2)\n",
    "\n",
    "def TanH(x):\n",
    "    return (1-np.exp(-x))/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def Pool(I,W):\n",
    "    PoolImg=np.zeros((len(I)/len(W),len(I)/len(W))) # W must fit an integer times into I.\n",
    "    for i in range(0,len(PoolImg)):\n",
    "        for j in range(0,len(PoolImg)):\n",
    "            SelAr=I[i*len(W):(i+1)*len(W),j*len(W):(j+1)*len(W)]\n",
    "            PoolImg[i,j]=np.inner(SelAr.flatten(),W.flatten()) # Now this is just an inner product since we have vectors\n",
    "    return PoolImg\n",
    "\n",
    "# To automatically make Gaussian kernels\n",
    "def makeGaussian(size, fwhm = 3, center=None):\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:,np.newaxis]\n",
    "\n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0 = center[0]\n",
    "        y0 = center[1]\n",
    "\n",
    "    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n",
    "\n",
    "# To automatically define pooling nodes\n",
    "def Pool_node(N):\n",
    "    s=(N,N)\n",
    "    a=float(N)*float(N)\n",
    "    return (1.0/a)*np.ones(s) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#################### Define pooling layers ###########################################################################\n",
    "P12=Pool_node(3)*(1.0/100.0) #factor 1000 added to lower values more\n",
    "P34=Pool_node(2)*(1.0/100.0) \n",
    "\n",
    "#################### Define Convolution layers #######################################################################\n",
    "\n",
    "######### First C layer #########\n",
    "C1=[]\n",
    "\n",
    "## First Kernel\n",
    "\n",
    "# Inspiration: http://en.wikipedia.org/wiki/Sobel_operator\n",
    "# http://stackoverflow.com/questions/9567882/sobel-filter-kernel-of-large-size\n",
    "\n",
    "Kernel=np.array([[4,3,2,1,0,-1,-2,-3,-4],\n",
    "                 [5,4,3,2,0,-2,-3,-4,-5], \n",
    "                 [6,5,4,3,0,-3,-4,-5,-6],\n",
    "                 [7,6,5,4,0,-4,-5,-6,-7], \n",
    "                 [8,7,6,5,0,-5,-6,-7,-8],\n",
    "                 [7,6,5,4,0,-4,-5,-6,-7],\n",
    "                 [6,5,4,3,0,-3,-4,-5,-6],\n",
    "                 [5,4,3,2,0,-2,-3,-4,-5],\n",
    "                 [4,3,2,1,0,-1,-2,-3,-4]])\n",
    "\n",
    "C1.append(Kernel)\n",
    "\n",
    "## Second Kernel\n",
    "Kernel=np.matrix.transpose(Kernel)\n",
    "C1.append(Kernel)\n",
    "\n",
    "##Third Kernel\n",
    "Kernel=makeGaussian(9,5)\n",
    "Kernel=(1/np.sum(Kernel))*Kernel\n",
    "C1.append(Kernel)\n",
    "\n",
    "######### Initialize output weights and biases #########\n",
    "\n",
    "# Define the number of branches in one row\n",
    "N_branches= 3\n",
    "ClassAmount=3 # Forest, City, Water\n",
    "Size_C2=4\n",
    "S_H3=((patchSize-C1[0].shape[0]+1)/P12.shape[1])-Size_C2+1\n",
    "S_H4=S_H3/P34.shape[1]\n",
    "\n",
    "C2=np.random.rand(len(C1),N_branches, 4, 4) # second convolution weigths   \n",
    "W=np.random.rand(ClassAmount, len(C1), N_branches, S_H4, S_H4) # end-weight from output to classifier-neurons\n",
    "H3_bias=np.random.rand(len(C1),N_branches) #bias in activation function from C2 to H3\n",
    "Output_bias=np.random.rand(ClassAmount)# bias on the three classes\n",
    "\n",
    "#learning rates\n",
    "n_bias=1*10**-2\n",
    "n_W=1*10**-2\n",
    "n_C2=1*10**-2\n",
    "n_H3_bias=1*10**-2\n",
    "#Labda=5*10**-3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": [
       "iVBORw0KGgoAAAANSUhEUgAAATQAAABPCAYAAABlEzkpAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\n",
       "AAALEgAACxIB0t1+/AAAIABJREFUeJztnWmMbNtV339r7zNVVd/uO7z38BjMHAiKMZMRYLsfASkh\n",
       "DF8SJShRUCblQ0hIUMIQKaStKEoAIUiE+JBAoiDIIBGCQsIQSLjPYMRsYsB2YhsMnp7fe3fovl3D\n",
       "GfZe+bD2qaqu29VV9/lieN31v9rap6pO1z111jn/s/YaRVXZYYcddrgMcH/YB7DDDjvs8LiwI7Qd\n",
       "dtjh0mBHaDvssMOlwY7Qdthhh0uDHaHtsMMOlwY7Qtthhx0uDTYSmoj8aRF5l4i8W0S+6WNxUDt8\n",
       "bLCT7eXEVZarXBSHJiIe+L/AlwIfBH4F+BpVfefH5vB2+IPCTraXE1ddrtmGzz8feI+qvg9ARP4T\n",
       "8NXA/OSIyKWIzFVV+cM+ho8xroRsd3K9WnLdRGivBN6/9PoDwOsf+vLvsfnop+Doa4BRGkPQkdBW\n",
       "nnbg6SpPO8hoB55/8U8b/tbRU0wYMmXAlMHK9mC+/T+PfpnPOfozTNfuu9i++63fS/kN30w3zulO\n",
       "c7pxQRjn6KnAGDjF5v96BG84Sgd+1a554BFke/Q/4OhLsPM2SfOacfRB+MYhjFsYN2lu4TTYqX/A\n",
       "Yv7vwFcCe8C1pXnkYZTDqEhzDt8+gaNXsri21oyjn4ejr7Zjl697fCfrJYSt5Ar/JM1vAb4cKIEi\n",
       "zRVnbmJGwPcB35j2WRrOg8eYJMO26yMojyAAXRoBiAGogWZpfAfwN3j4YqqXRpPmnwYOgTev/fGb\n",
       "CG07Jq/T3KXt/od5wCsiinNp+Ij3ggtK1gVyaekkI4gniKcjoyXHE3BL/33EEbDPGwobWtDGgk5z\n",
       "upgTNEM7R5zZ0JmDmcCMh0eX5quL7WRbYvKssIty+SI9b2QgJXixP8uBUu2jFmgVuvQ6U6jEvroS\n",
       "GyVQZlDkkOXgC3AFdk1XF4xy6VjLj/bUvKSxpfaVp9mzILE0ywDcAFwFrjQBdA4qD86Bd+DELPA+\n",
       "fVWGCTQDXlB4Igm5ExP8nNScjeAhZjBzJuhYGuFFhQiox/6DXtnQ9Lo/7vOxidA+CLx66fWrMcY/\n",
       "g6Mfs/n278Htt8Hh685+LgpOFaeRLB2i7yJF0xKdQ72zEyPMSaumwBEQFEWIS2RWUzJlwCwOmHUV\n",
       "TShpu4I2FMTGEcYZ8dSjY4eOBe21sn7+zdvw3tswPdrw8y81tpPtT8Dtd5sSe/jxcPjKDd+agxuC\n",
       "91A4iP31KKARuy4jqEKhsCc2Ri4NgWEOZQlFCVlpBEnNwxrZcGmM4PaH4PZ77ZivMLaSK9xO8+8C\n",
       "vw+8jvnJlAqyCvIK8tK2px5u5VBkkDsTbi6mqGVqPJOnWYFPXn6KAa3YaARaD43a+y94GAzS5w7a\n",
       "HLQAnbJgyncDvwW8b+m4z8cmQvtV4FNE5DXAh4C/AHzN6k5HSaG9/fFw+CqMNBIEEFWcKp6IiL33\n",
       "xtcLRdOimV3xIoo4pU2kldPhE6G9+vA1BNz8sxkVE4bUsaTpKuq2pG1KurZAXvcmwmlGHHvi2KWl\n",
       "pizI7BR46hA++whuHdpB/vJ6FfYSYzvZfi3c/k04/GQWqwFlrR5w+KQ91LOezBRctGerBiM1xeY/\n",
       "SSI0B3s+EZqHqjAyKyrwlSkKh56zBNavhJbG4Wvh6AAOP9eO5c0/8nhO1EsMW8kVviLN78fIbA87\n",
       "kXumoWWFqclVYWP4JiO0gbdRCQwwxS7Hnk49qY3eCC/XRGD9jD2Ups7IcQpMBfSNJuSZg1kGWkJX\n",
       "kZgSu3JeB3wK8PY0/8zaH38hoalqJyJfB/wUpkN9/7nekolNh09yhszsS4zQRCMeQQCH8vTnepq6\n",
       "tc/FlqKOkDSwhowWR0yE9okcL2los6ShNbGk6YzMmllBWxfoZ37JnMh0Tmic1dBOgeuHNl9RbC3b\n",
       "IRy+nq2X54evgDCFLJGZj5BF+w9UsGWHgkSzXo8SoY18IrUMysI0M19BllY/h7e42H6WCO7w87Gb\n",
       "7Ipia7nO1+WvxU5eb8G8BjKELLO1/zAJZfQl6cnj4Fqa9xKp9ea3Iqndn/lGI7IGqGVhLpsKPHB2\n",
       "352m7fJPwaQDl5lm1gWQLn1hH1WmmLr3mRt//yYNDVX9CeBiJb4nsXD+xz2JIeAkoC5d7SqQ7Gou\n",
       "BhwhaV8DsiUNTRECjo48EV7FlAFtTEvNpqCbFXSTgjDJ5iT2kHa2SmpX24a2nWxHaXast86svC9i\n",
       "qxAXIUYogpGa9vs65pr6KC03ezIb5aYYuNJWPm5gS9jzNLIzy87l964wocGWcp0TWsXiBF4DDkBG\n",
       "pmKXAsNEYNccXBc4EJv77b1EYmU/or2uBRp31rZ/Chw7uC82F5oulMwulC5CnZ52c1tZxMisYS3B\n",
       "LGEjoW2FjYSmZtoTTWtQew8BcRHnAy4PeA1MqCloyQg4iQALG5p6GnKzoemArivo2pxQ53TTgm6S\n",
       "E8d+vRdu1ZY2fSy//lJDh2nDLcyzm4jNpW2f7GV0pqn1S1AUCEZqIzElYOjNdjbIzWwzt1MPeJiw\n",
       "1i07h+l4rzihbYclQpMBMALZA/bBD01BGqS3DoDrIDcVbtosNyLcVORaIrFSkSrOt5kJ1A6tHdQO\n",
       "akEfCNwVdCBoKZCJKTeC2VV7R12GOQ7oQJMRTmt7vQGPh9DSknMLAp1j4Sgw25oSUBUyF/Eu4lzE\n",
       "JbsagAYhRk+MGSEkr+Y4I84dAHI+aV00X3ENbRu0A7tERBSJas8kVXtIrbOl6cNDHPgmPfid8ZwA\n",
       "VWlLzLw0j6aUGIltqY3pEHSYbpKhoAPQqqfezTfA1UV6UvkB+BJ8Dpk39/QA3K2I3FLkiYi7pcit\n",
       "SH7Qku+35ActxUFDvt+SjTpc3uGKgCsCvuhwWSCWniAZ0Xmiz4iZp5OMVgsal9MWOe0gp93L0ZEj\n",
       "VoIWDvVCJEUnhAy6HEIJYQAhbvxVGwlNRF4N/ADwFHZ5/mtV/VdndtqgoZ39wjSrJmdBtCd5f0A+\n",
       "4H3EZYr4pNEhaHAWktF5QpsRuoIwzginyfi/bC/bltSusIa2lVyBbuBtfxQXTV6uF8sym20IFhBn\n",
       "ns/cJVsa4NTIrCzNodYvM+da2QYngL1nRBaHQhw44kCuNKFtK9e5LcEN7OSXyYNZCLJnROafDLin\n",
       "Iv6pgHsqMNibMBxNGI6mDNN2Wc3I8pYsaxdz1tJJbsPndFlOV+TMfMXEDZkUQ6bDIZO9IdODAaHy\n",
       "xNwTvSfgkaDo2EHjoS6gKUEHW/HLNhpaC/x9Vf0NEdkDfk1EfvqMofFRCC1BMA1Nkx9fxJalPg/4\n",
       "PCaPqCLeXPwahNh6Qp0RmoyuyYmn/mJv5k5Duwib5Qq0lRGawzRpQ5LNefHIa7Q2EXv4573nU82u\n",
       "lhd2P2WVKQuybNK5SEtL++iQOZmFNGJ5JQOle2wl17mG5gbmUq56D6aDA3C3FPdUIHt5h39ZS/by\n",
       "juHglIPqhP3qhIPqmP3qhFE+pshqCl9T+GY+N66g8SVNKGnygiaUjPMRx8UBJ4N9jvcO4HokjIUu\n",
       "zwk+o0PTfe7sYplkIHnyfAaWjB5rsY1T4Fng2bR9KiLvBF7BUirFiyG03vvpJeJEiCI4gSxGvPbL\n",
       "zXSEahpabB2x9oRZTjc1e5nFmQmM3aOR2RXX0LaSK9AmDc3LQt03+2fv2OFim5r2f2PXKBiZ5clZ\n",
       "4AvTzPwgEdpF2tg57/dLzTBwdANHGHjCFSa0beU619B8aev9qkiuZkGug9wyzSx7WUv2yob8lQ2j\n",
       "csxBfo9b2R1u5Tb2/QmVm9mQKZWbUboZM19ZnKhWzKJtn3T7DIa3yNsa2kjXOepZYSuxOZl5UzTU\n",
       "YdpMDl1pzoItigM9kg0txba8DvilMx+8KA1N03cCKE4gipJpMJLrl51qN40GQVtvhDbNCOOCOBZz\n",
       "/45JwbM7De3FYK1cgbayS0TFhCuoBdMk584ZXLDsFCyGwKUwDu0zC1LgrCTbtCyT1qblZhpxIMTB\n",
       "gtS6wr+Y03DpcJFcF0vO5IWpcnMz7zu4obgnjND8y1vyVzUUr64ZZqccyH1uued5mXyEl8mz3JB7\n",
       "DGViCYgyYZjmiQ6ZMDwz39Ob5NqARrromWrFuB0CikYjM1dHZGL3O+qhK4zMnLANXW1NaEl9/WHg\n",
       "61X1TARXk1KfBCNVWXLLn7ssYbE/skxsEYc5AiQDQiKzKEZojaC1I07c0jKT7chrojZmaieoUcvD\n",
       "ueK4SK4AdVYAEGIghs5clco8La1/4EiKyUjPp/OXnf1+vfdTOWsv26SNDYFk+Cc5A7rK05UZbZHR\n",
       "5J42y+iyHaFtkuvcy+lTnMwgs9iyA0FuKNn1jvJgxmB/zODahMG1MTf1DjfjHZ4Id3iie54nw/Pc\n",
       "iPcYxAnDOF3MOmXgpgxlytRNmLghUzcgc4HOezqf0eY5jcvpyozp/pDpfsAdKHriaW+kYNzgoclg\n",
       "mgIZz6RCnY+tCE1EcuC/AD+oqj+6+vk/vp/28/CmBg7TErhP5zxzcW9aDSznh5WccfPTkqKNeRHL\n",
       "S4U6QBNg9rPQvoULVYorgE1yBfiOI3tauRD54i/0vOn1JVqYEHOCOXaiJs/nQvOeY9Mp3tb433sz\n",
       "0+iN/22V0RQ5TZ5z+62Rt/5CQ/RXu27pNnKF5CeoHXRvhMHTRmjXwd1Qims1o9GYa+Ux+/6Yaxzz\n",
       "VPccT82e59bsDjfr+xzMTthvTinbGVU7o2wb8rbFd4Eia9G8hlxwuZLngVBk1FVFWxWE0qOV4LLI\n",
       "iT/gQdkhQwj7ObMbA4tha51lFnS/CPVbgMfj5RTg+4F3qOp3n7fP3ynSlxWQe2jTUs5dZF9Zh57M\n",
       "WuZR5WcIbYYR2qOGaNTRyKxtQV4P7nMg9l6wb3vEg3zpYxu5Avy1o1cAUHQtZdtQd036e3N1eo2o\n",
       "Ko5oD691Al8O41jGlsZ/09AkLS/dfInZlhlNljPLCl73dMFnfFlBm1lQ5ve++f4jn5eXOraVK/wj\n",
       "m/Y8XE/OgBQ8665Hyv2G0XDM9fKYm9kL3OQFnmxf4InpCzzx4A43Tu9z/cEJ+5MH5LOWfNaQzxqK\n",
       "WUdWB2LZQdXgKiWvAkXVmUZ9LSdc8+ieIJnis0CRdbgSwiij3h/gZikwd+rggbesnukbTCEB4DvX\n",
       "/qptNLQvAv4y8HYReVt671tU9Sf7HcZ2jZtSZSsSJKW9bEGqZ9FrZn11h/M0tOUSNtuSWqPQddC1\n",
       "0NWgDVfRrb+EjXIFmCRvWJAG9Yu8W+cD4hRVwaes8z4bBLjYWcDSZ9sEzC4FzcaBIwwXHs0mz6h9\n",
       "Tu0LZq6idiU1xRb+sEuLreRqkbNY5YzCpYwAywCQG5HiWsNoOOGgvM8T2Qt8HB/mVneXW5N73Dy5\n",
       "y82797h+75jRyZhs3OHHAT/ubEwCxbDFj5R8FOhGHdWoxh0ooclQdYhX/CCQSYfLIJQZ9XDI6bUG\n",
       "aWJKkxLzvOZiVT7YbErYxsv582xwL0zaM6do7pLXvtzMMi660gQjsz4oeJnQ+sz95SXno2hoIVp5\n",
       "ktBCbCDOsHSKq4lt5AowZQBAdLarOEV8xGmH+Jh4SXHiUNHz5buO2IQLbWarn+mq8X9gNrNGcmpX\n",
       "UEvJVCrqK1w/aFu5zu9WJ1AIDMRyMw/SknO/YZg0tCf8C7xMnuVmd48b02NunNznxp1jrj93wuDu\n",
       "FDmJ8+FOInKi+P2OuB/Q/Rbdd+i+I5tGNJpm5qqOrG3JaQg+oy4HnA73KdoGF9Xu8WMHQzHC9dst\n",
       "9x5LpsBpIrRKF5pZHlI9t02ez1X7Wh+HdN6Ss8GWnBMuJq/zcjfjck5Yv27duTk3YU5oYk9VWapM\n",
       "5zJTv4VUHksUlfgwqa16RPvXjvPTms553WtnfbxZV3mzn3krNWUlpSzH9yoT2vboNTTmaU5cI9nQ\n",
       "IsVezWg45qAwDe3lfJjr7TEH0wccHD/g4M4JB88+oPxIjd4Hvbc07oPcCMgNbFy3OW878IobBLJr\n",
       "LWVnkquzAaflPvdGNylig0iEicCdlPxesI1yBjwuQktzp1jNq8h8iRix3FOXmdbY14VbWwR4hHHO\n",
       "Ohtar6Gt1cgUZinJtU3Z0RqX/miyNO8IbRPmS04sirtNBQJmVBQ0ZC6SZYEsD2QxkvVPsD5Oo2CR\n",
       "kzli8RyZpjFYGdX697rS0+Uueco8nThqSmaU1FTM0mjma4Ud1iJbmjNSpQxS5YyIzwN51lL4mkqm\n",
       "DJkwCDPKpiabtbjTAMdKPIb2AbQTs523LbQB8hbyGeRjs6vnDqRS/PVAPm0pm5oqZoykoHIzCl+T\n",
       "ZS2+6JA+H7QglSSSxXHChZaibb2cHquz9AFV/crVz5cJrSefnq8UyFIOX2b5qOv1YcEu8prtCO08\n",
       "UptghNZ0Fl0c+oCn82pHX21C2yRXWGhofSXhZTLLpcW7iM8iPkYyogXgij5MZudVVK5ZVJrtR3HO\n",
       "eyVoIYTCEXJHyBzBuVQjL19UME6j3VDV9Cpgo2x7jScjFWbsCU2RMuKLjixrKH3NwM0YMqEKU4qm\n",
       "IZ+2+NMIx0o4hvoUpmOY1jBrLcpi0MBgZtEgA5cchFXEnQayaUvZ1nTBahxWMqXwNXnW4vKQKnZE\n",
       "WwoXYseWyeKYP1pCA74eeAemlD6EOaGBZc33JzVpbIWz49IUm+bjGg1tG0JbXnKep6FN1R4RTWeP\n",
       "i9ire6uehF1kLRvkCgtCsyonVngzoyWjI5NgAdCpwEBfYt2e+CxVKz1n9DbRfGVk57yXRswcMRNC\n",
       "5ohOiOLo8HRnjionbLs+udy4WLZzDU1TgUbmZYCkjLi8O6OhjZgwiFOKpiabmoYmx0q4D80UJlN4\n",
       "MIMHqX/EtRauzSxs0SkUHTBU/Gkgn3YUTU0IQodP2QU1WdaYhhZXNLQs1aNKxWDnJf8v+FlrISKv\n",
       "wroo/DPgG87b54yGlryakiosEK0SiMrCvqY9UT30n2Ec0zsgew/psg1tk4Y2VXMAhA5CMv7rsmv0\n",
       "dGlc3dynbeQKMEmEZmEZwYhrPkfEKS71jRCvuP4GCRtGb5bwK8Od814a0Vu5GXVCdMLCouceOrKr\n",
       "jK1k29/589LZuijQWEZ8EcjyltL1S84xVZhRJg3NjRdLzrq2SIeTGu61cD9FR/VkVgYINWRDNQ1t\n",
       "1lI2QLSsk8EZDW2J0EqWHnSylfq1jYb2XcA/BPbX7fAgzV1PUqnWlQTALcI4st6k1V/Qq7hIQ9vW\n",
       "y1mreSM01VDSvivKamG0B1xlQmMLucJCQ5unqqGLITov1mjVU9If6Tkjrnl/2UEgGwapUocsUq/0\n",
       "7BEtHemVxmbZnllysiC0UpGi19As2XzgZgxlQhVqsrYjm4a5DS0cQ91Z0dnjFu528EK6/XoyGzbW\n",
       "D4WR4sZmQ6OJuBBQoHLThQ2tJ4feplewsKFtoXhfSGgi8hXAc6r6NhE53Px1C8ydrHr2vYfik15M\n",
       "8O3q3583X/gHF+586fEocu0J7TzSOEsgqaCQYqyzSlybsHGf5eoeOi9fJA9t65WmtBd9zy57omXV\n",
       "Ub04n/MUt5WHV9+vfC5yXYyHr4Wl71u+elY94S8CmzS0LwS+SkS+HDPv7ovID6jqX1ne6eeWvuyz\n",
       "gM/zi9LKQ2dF/IpUxM+VIAVrK46y2h+h/3HL6VD935133fqUAxYyCIXlg3aCqQi9mvDbwG9gKt+V\n",
       "xFZyBfjfR78AGF284vCTednhpy6WduqsTl2QpVnsfF+03OyWtvuejmuWmYvPbUkrPqY5xcNJTC0P\n",
       "I8/e/n98+PZ7uKoPqoTtZDs+svmDCntvgte8ae6w0drk27qcxpfMdMBEh+CFWLQwENweZPsBN4Gy\n",
       "gVENTWNLS6dwo4CDAkbp3nclcCDEPU9b5TRFQe0KJgyZxQF1KK36dONT6W5JHaIEPnQbPvSMFZ/Y\n",
       "gE1NUv4RKUdCRN4E/IPzLvo/n+ZBakW22sWnKKyDT54aX8iyG381/qhvupAzb21Hn2jfE9oA6+lw\n",
       "Hpws2mG1mox3buVR8XrgT7BwCvzkmi+7nNhWrgCvPTIHWTA3ACdp7sgJ6onBW1mn1qOtIzYutSTD\n",
       "Ru+TWR7L7/UG6VUnwOp7heLyiOQBl5v9zrmAl/5oOg4OP4tbh38Cn0JHfvnN/+vxn7w/4thattmR\n",
       "zbcUrmP3ytz77AiS0fmCJiuZRmvmLR4oBDdQsr0AB4KfQTGFYQbBmQZXBLiWw7UKhgMoU2koTYTW\n",
       "DXLqomTmS8YMmWnfijIntlkq250IrRG48TTcfNpi0wDqN6/9/Y8ah3buo693o1QsNbxIY5hbjmdW\n",
       "Ljr4PFTEb7g0ryO0PgxguUTzuY4FgdrbY0IxbW3+M+f+1zR27v2EtSrNNMWh9S0El0enOSFkxNYT\n",
       "64wws/JO1GI3xoxFeMa67eX+AcvzQ9uKKwM+duYGcAGfd+S0K0fVkF3tlLZVnC/bPuC9kwWZNSY3\n",
       "rR0xVcSoQ8lMrW2kd4orlKyKxL0WTYRW+uQAiObNHDbWG2JQwWAIxR64PYgHQhgZoTV5ydQbUU6j\n",
       "dXDruoLQeiO0nszmXnF5bBVr7ayoPgM8c95nvbJUyWKpOcpsDFMHH1emRsyr5WLO69jTP51XCS1n\n",
       "kUmwTkMTkkaWHhnLrtezO7EjtIvlCsthG0UKXF0EsTYUhJBbSfQ6J0wzumlmeXgTzOeybl4NrB1e\n",
       "PEun+NjhafGuw+cdXtvUA6xORzajoqa4wilty7hQtj3n92TRa861oI0j5J6uy2lCySwOGDMi84Gs\n",
       "CJSDjrDnFxpaimDIO4s/a92iEnExgvwa+H2IB26+5KyLgpkzQptpRd1raE2Wmqq4Rfu7VlIX9s2/\n",
       "+bFkCpwhtLTM7Nv5Dfrlw/JS8zwy60nuIg1tecm5TkNDQD1Eb0+e3ns2r0jYu9Qci+zTHdahJ7RZ\n",
       "SiuaMGTKwDrXa0UXCkKb09UF3TSnG+fzopsXpqX181J/2/m8vD0P4VEyaclcY7XrQ4vXhooZA1Ik\n",
       "O/k8uGSHDeiW5pakEZFIzRHyjLYoqKN1WJswpPQtRd5RDRpiIjRXp5CxDrSBOLXbT/pWhEOQayAH\n",
       "oPuLJWdTJA1NzYbWhIKus4ejzm1onI1b/FgR2igpOmW25AAolrr4nKeJrS41lzW0koWh+DxCu0hD\n",
       "O4MlI2LnzHccCwvriGpnfocL0ac+1dGe1LVWNLGiidbgOUwywjgnnHrC2BNP/cPhfutejznrqznP\n",
       "Mzp/aGkiqyyFa2Bl23O1bAVnMXHiIMhOrpuRtNiQlnZTsQfRfWs402jBxA85Lg64U92iYkKTlTTD\n",
       "krCfEacOOhjmGXJNkeuLBHV5oMR9oUtJ6f2Y3Bpw7+Z17u0fcG9wwL3sOne5wZ1wi+P6gMlkSPOg\n",
       "QO87OFZ4oClQXs259ziS00XkOvB9mBVdgb+mqr+4vE9PaHmeOviUVqpcejvItmR2kVPgvLzAR3Fm\n",
       "tQ46b22xupjW5I+ni99LFdvIdr7k1JJZqGi6kqYrzN5R56nrlo0zmtlqgYB1r+H8ZPaHXi8CacX6\n",
       "sANCV0aaLJVrzxQyCLsCjxvlOvfwRzGvYl977L7Vm2tcampSXacKU7y2tHlBOygI+x4NgnNKN8gW\n",
       "ZYP6EkKTjjDK0vDz7dODEXdvXOfO/k3uDm5wJ7/JHW7yQvcEx/V1xpMRzUlBvCdwHziNlkfVpADW\n",
       "x1Rt418CP66qf05EMubFyBfoCc0XSTtLXXxcRfIU8PDS8qIl53k2tG29nOtQS2qLlSdngWNnQ9ss\n",
       "2zmhxYKmq6gb08ysW32eSqF7ayN4Xpf6i16PV/6zDcRmEWbOGhYDikOC4oqIFHaxqxOCv/Ia2ka5\n",
       "LjS01C5ums01NK0cTV4wrkYc7x3gu9b6RWc5YWBLTXGKLwLhmqTCjn2RR6BW2iq38IyqSNsFJ8N9\n",
       "7l67wZ1rN3l+8AQvZE/wvD7B3e4JjusDxmMjNL3n4L7CqcI0VZkO66Lxz2JTYO0B8AZV/VoAVe2A\n",
       "49X9hn0lkiL1LO1bkvUG3/NKw6zzcvZLzpyz0eOrS86WR9PQnAPJzJYWHXQZj1598vJgW9n2S84u\n",
       "5jSdkVkzK+hmBWGSo2NJpLbS4+Gxa2hGaFHsKadIan4MEhOZeSGq0D6m/tkvRWwr1wWheSt+OpFU\n",
       "UNHaADaDgvHeCF+3xGC5vCH36LAns4581KC1UrU1XTujbAXtFGmjFd7MS+q8ZJZX1HnJ/WKfe9V1\n",
       "Xqhu8Xz1JB/JnuJ5nuSku86DpSVnvCdpydlraF0qMrHZzblJ8p8APC8i/w54LfBrWNOFyfJOvYYm\n",
       "yWbmljv4rNPG1i09+yXnOhtaxcJI+CiQ9CU9ma1t+31lsJVs59U2NKfriqSZFbQTa/TMKfOeqLps\n",
       "G/sD0tBACAgitqzU1LVYvRBzR4iO7AoTGlvKdU5oMbPNqYMHDgqIhaPeK/AHI7SGpssZMyBmggxM\n",
       "M8tHLUWocSHQRW8mrqi4GMhiR+tyZq5g6gZM3YCJDLnvD7jrb3DH3+I5/yQf8R/Hc/pxTMKQaT1i\n",
       "OlnV0CJMUqGJuN1Nv0nyGfDZwNep6q+IyHcD3wx86/JO/7w/VQ0c5nC4yZu50sVn0QSjbwkvaI5F\n",
       "/QuWM+jV8s1KRbqIaGQ5X2M5/eZ8SNLOgPFt0NuL3a8mr20l27vf+r0AaOuQz30D/MmnCdOcMM7M\n",
       "brZaJOCiIpuTZOSdYt23Zpq66UjSxpM81xKbLHI5528pIhl4pf2ln0d/9eeQ/Opq3mwpV/h2myYe\n",
       "8jdYk5RTD5miudX+n+1XxANoTjOmpyV51pFLSy4tWdGRSUcQl1rXDZimFnYDKvM7r7Syu6s3eUGf\n",
       "4IV4izvhFne7W9xtb9I8KGkeVLTHJd39DL0vcByN0GYdnD4D05/jcWhoH8DqKf1Kev3D6eScwdGr\n",
       "0sZ5DoC1ZCZo38knlVaOlSOUnpA7YuassoLYxe684vKALzt87Mik7ZveoUvtrfRCUutxCOXhIlHg\n",
       "/vrI40uMrWRbfsM3ARCmGfE0I4z9i1tajpM9pI5Wpy4m92Z05oFuvNW3n6vlbNTYFs4CqwXiX3uI\n",
       "/6IvxlUHAztPAAAMIklEQVQdCEz/6Xd9FKfnJYut5Ap/3aY8GbtnLWSZRcf6jDi0e7HL89QIGMbF\n",
       "Hsf5DfIsQu5os4Jjf53KTRfNht2USmbMdJAaDKeGw7HiOBxwp73Fne4WJ+0Nxt0ezayk/WBB+HBG\n",
       "eM4T7zi4B5wojDs7Lvc5kH0GtDUm9O9Z++M3pT49KyLvF5FPVdX/B3wplgh5Fr3JsQ/R2MZmlsgs\n",
       "Dh1xKISBEAZWkdQITYjzazvl7RURp8HikXxDwKPqiSjLfYe2Rr/71WsOtLVsu7EZSOPUmTezdwD0\n",
       "pLYtsU01dd5qoe1Sx63OljxdZs4aMiO4Vea6kNgWhIYoCrhwdb2cW9+zpGVVjBa4OssseEztHGpl\n",
       "wbXizZ4Ug2My2COvAlSOtiyYViOGxZjCW1WO0tcUvqbwDXUoaUJBE8r5GDcjjmcHnMz2LUxjtkcz\n",
       "qeg+nBGezQnPefSOQ+8BJ9EegLPGGv/G7Urmb2Ns+DvAD4lIAbwX+KsP7TFM87JHc52d7EyN+J7I\n",
       "FnXiu8wTvCP6pKFhKxHpNTQ6vO/IshZBsQIknmjRszxSmv6Vd4Ztlm03tgtaJw4dW4PnmGxmj6Sh\n",
       "9YU3uw66JhXebCwusE1eJRULrelXjFtoaH19jSgOyIzc4pVecsI292xvwAwKbSKzWFpIU4RYCOI8\n",
       "HaBBCK1nsrcHI0c7KpmORpzsXaesZmRZS561FvCcNWR5R9fmdF1Om+auzZnNKibj4ZnRPCiJz3nT\n",
       "zp7zxDt9yIaa7axprbZ37NNMLsY2XZ/+D/B5F+7Ua2g9oV1k9J8TW7/UTGQ28Dact/LKYoX8ljU0\n",
       "kTjP4fNly6KGiaASkXk/7y1xxQltG9mGpKHpRNBTQcfy6OEZfZ26EMy4GxoIqU5djGbr1eSs8Zyf\n",
       "qXbBa4tNM01NJCJXnM+2umfnGppAUxiZtQFqRVtBnSOooNEKD8hM0QNPe1Aw2R9ZKe7YknUtvgi4\n",
       "osOFgCtM6QhNRmw8sckIrSc2nm6c054UNMc57UlOc1zQHufoHUe8I6advSDoPbEy+l3q0tbVj4/Q\n",
       "tsIyoW1DZiPQAalprBAqa0vWVhmduFQMRoiyqHYl3so7uzzg1VKlIbnykRRs+Yi44oS2DbrT5MKe\n",
       "svBivhgbWp1yarXDMqBTMmcg2dFSvgy6cGZtqaHNnQWoXQdbJDHv0GtoDmJl/WrpTEmYpYdEgNj6\n",
       "VB9VaW+WTKeKNIqEVOBTzUlnbSKj1TeTCI1Da7GczJmzhPMHgt41wtK7i23uYSN1j+IeqVJOKlOt\n",
       "/fWy6hZ/GNtkCnwL1rg0Ar8J/FVVPVvV+zwb2hKZ6cgcAAx6JwCEgactM9o8o8lzWp9Ru5yakjbV\n",
       "iO9LKQuKEytgU9BQiCUjt1nE5xFXKm0KJA6oXeSaPGEq6x0FV5zQtpGt9jWoVnvMXERkEz3beavT\n",
       "tMSccrbr1sT+6760k6Y825CbXad2yQO6Ylfb5AW94hraVvfsvDB/DjoBnRfwN82odujUWXcjsdhN\n",
       "jbKQyzSZHfY0lcvWefluSk0VV5bKANVJq7+PhWQcK9y3RiucRFtiTmJyGkUI/YW1XM3ggmYCCZsC\n",
       "a18D/E3g01W1FpH/DPxF4N+f2XHVhraimencAWAamQ6EtsxoipwmL6h9TuOsCceM0krTkJnRf76Y\n",
       "iPO+QxU1QyY0ztJepFiqoCmK6sL7GTnHyNzjChPa1rLtG0aslj2/SCObRZgFM/6HkJ60NQ+zYSK0\n",
       "1bK2WqaAzwxcEpL6rQNwr7KGtrVc5+TQd7TJWEQwt6Yx11nyfPpF9ZraLWLW7vWNgFmM0ll4VV/+\n",
       "Z3lMUmzZg3h2HncWb1Z3ZmPVgF0fD1hcJzUfNaEBJ1gY61BEAkZRH3xorw1LTh2YNzMs2czaIqPJ\n",
       "cuq8YOYLarFmsXUqS9ORz8MyBE1pyR0lVmGhocA5RbKIlGrLj+T1j/MWHiB9zNJ5nHal4y+3lG2v\n",
       "5a82d74o8byOi65bobUbZN7XYXXn1Rw9SXa13EIIJLcl6aOQ1NXW0LaT67zEUl8vsL9BopXN6HKo\n",
       "C4uWj7k5bmpvcWsPfCr7JFDKIlWxkEVBzlYW9cz6qhkztcj/aTg7Zo2NujWH0bxL25nelEvHvB6b\n",
       "wjbuish3Ar+PPaN/SlV/5qEdL1hy6rAntIU3Mwy8pUa4nNoX1L5kJhXTpTpbqxqaJ5LTkdNQMmNA\n",
       "btUVsp7MxEI9MkFU6eOZLEZtjffzCmtoW8t2WUPb1m7WqS1butZqMp/purVKaitkRqouHKJdv9Gl\n",
       "YgIrx3WRtnaFNbSt5TrXdtI5B+xJkOoAdRXUpdnX2jK1j8wW/TsLt1JVWFJLPLExr1AsSyWKMBNE\n",
       "07eZ7L2YdepSXJuzSPtOSJOlMWMbDe3CgB0R+STg7wGvAV4B7InIX3poxxSOcfuDnL/kHPUOAPNm\n",
       "tpXnLb8YacoiaWgVU2f1tuq05GyTDU0R3n/7fTgWNrR+yTlwU8psRlnU5FVDNmrRX38Gv9fhRgHZ\n",
       "i8iePlxvawQ8f3tRe+sKYmvZjoG3395+uXlyO9lCkobW9Qbd1TaCD7C+Dg8Z4Gz/rra/r4N93/Ht\n",
       "7ZwPv7W03xXE1nKdFz/7bRba0APgGPQYuhPrIDyZWMPNO8/AnRae6+DDEd4f4X0KvwO8V+A9S+PX\n",
       "n4F3p+33pvE7wO8pvF/t75/r7PvuPGPfP5nY/9c9AL1vxzFfcvYxaO9ik5a2adH1ucAvqOqddLJ+\n",
       "BGvC8EPLOx2l0u233wtH+3D4edjyswIqQUshVkIshVg6Qul461sbPvPLPA15GsWczHrtrHcK/P7t\n",
       "3+XJwz+OJ5AnUuvICOIJ3tORzf+FX/x5si/8YlxwxBAhKNKbcfrxztvwliP4Y4cbfv6lxlay5ceP\n",
       "4H234VWH8OQhHBwurq8ZC3tt/7q+jfVsSE/7M23SZyt/+H+BT8Muw6UOw5rZiH2DTwVuw/RwpXEK\n",
       "Z18/ext+7Qjed/h4ztBLE9vJlZ9O8+9hWtpnMG+WqsHi00KvvXngrTD7IhZxNUmz7j/OWHQ3r5+B\n",
       "8ulFQ5w+rzyy+D/mH/5C+r9XG+7WS+Od2LXyO1hY3XpsCql+F/AFIjIQEcGijt+xutPRn7Vx+Glw\n",
       "+BkbvvGPAj71ED7xEJ4+snE1sZVsefoIXnMIX3wErzz8WB7fo+OVh/aQ2sl1s1w5TOMTgE/62B3d\n",
       "i8InAX8KUzoPL9zzQkJLAXo/APwq8Pb09r/+aA9vhz987GR7OXHV5Sqqunmvi75A5KP7gj8i0L4O\n",
       "zQ5zXAbZ7uT6MC6zXD9qQtthhx12+KOCq1uWYIcddrh02BHaDjvscGnw2AhNRP60iLxLRN4tIt90\n",
       "wX6vFpGfFZHfFpHfEpG/u+F7vYi8TUR+bMN+10Xkh0XknSLyDhH5ggv2/Zb0//+miPwHESk3/8Kr\n",
       "iZ1cLycurVxV9aMeWPTJezC/ao5FTH76mn1fBnxW2t7DAkzO3Tft8w1YDM1/23AM/x5r1wUWFXOw\n",
       "Zr/XYAEtZXr9n4GvfRzn4bKNnVwv57jMcn1cGtrnA+9R1fepagv8J+Crz9tRVZ9V1d9I26dY1Nwr\n",
       "zttXRF4FfDnWY3Ctt2qp082/Td/bqeo5nW6As7luGWtz3XZgJ9fLiksr18dFaK8E3r/0+gPpvQuR\n",
       "KgO8DvilNbt8F/AP2Zxu/AmkTjci8usi8m9EZHjejqp6F+hz3T4E3Ndzc912YCfXy4pLK9fHRWiP\n",
       "HPshIntYA4evT8y/+vlXAM+p6tvYXFe773Tzvar62VjuxDmNIR4l120HdnK9rLi0cn1chPZB4NVL\n",
       "r1+Nsf65EJEc+C/AD6rqj67Z7QuBrxKR3wX+I/AlIvIDa/Y9r9PNZ6/Zd57rptaEtc912+Fh7OR6\n",
       "OXF55fqYjIwZljX6GqyoyEVGRsFSM77rEb7/TcCPbdjnLcCnpu0j4NvW7Pda4Lewik6CGSf/9uM4\n",
       "D5dt7OR6OcdllutjKXGoqp2IfB3wU5gH5ftV9Z1rdv8irDzw20Xkbem9b1HVn9z032z4fItON5br\n",
       "lp4cv4qt9X+dK5Tr9ijYyfVy4jLLdZf6tMMOO1wa7DIFdthhh0uDHaHtsMMOlwY7Qtthhx0uDXaE\n",
       "tsMOO1wa7Ahthx12uDTYEdoOO+xwabAjtB122OHSYEdoO+yww6XB/weQWYWepZVICgAAAABJRU5E\n",
       "rkJggg==\n"
      ],
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10775bb10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_plts=len(C1)\n",
    "for i in range(0,N_plts):\n",
    "    plt.subplot(4,3,i+1)\n",
    "    plt.imshow(C1[i])    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the extra information regarding the code in the following cell\n",
    "\n",
    "a random patch is chosen in the following way: the program counts how many files and patches there are in total, then it permutes the sequence so that a random patch is chosen every iteration (forest, city, water). After selecting the number the file has to be found back. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Determines total amount of patches and makes it easier to find back the patches\n",
    "N_F=len(dataPatchedF)\n",
    "Patches_F=[]\n",
    "j=0;\n",
    "\n",
    "#Determines the total amount of patches N_F in forest\n",
    "for i in range(0,N_F):\n",
    "    N_ff=dataPatchedF[i].shape[0]*dataPatchedF[i].shape[1]\n",
    "    Patches_F.append(np.reshape(dataPatchedF[i], (N_ff, patchSize, patchSize)))\n",
    "    j=j+N_ff\n",
    "N_F=j\n",
    "\n",
    "#Determines the total amount of patches N_C in city\n",
    "N_C=len(dataPatchedC)\n",
    "Patches_C=[]\n",
    "j=0;\n",
    "for i in range(0,N_C):\n",
    "    N_cc=dataPatchedC[i].shape[0]*dataPatchedC[i].shape[1]\n",
    "    j=j+N_cc\n",
    "    Patches_C.append(np.reshape(dataPatchedC[i], (N_cc, patchSize, patchSize)))\n",
    "N_C=j\n",
    "\n",
    "#Determines the total amount of patches N_W in water\n",
    "N_W=len(dataPatchedW)\n",
    "Patches_W=[]\n",
    "j=0;\n",
    "for i in range(0,N_W):\n",
    "    N_ww=dataPatchedW[i].shape[0]*dataPatchedW[i].shape[1]\n",
    "    Patches_W.append(np.reshape(dataPatchedW[i], (N_ww, patchSize, patchSize)))\n",
    "    j=j+N_ww\n",
    "N_W=j\n",
    "\n",
    "N_total=N_F+N_C+N_W\n",
    "Sequence = np.arange(N_total)\n",
    "Sequence = np.random.permutation(Sequence)\n",
    "\n",
    "# Make patches tractable\n",
    "Patches_F = list(itertools.chain.from_iterable(Patches_F))\n",
    "Patches_F=np.asarray(Patches_F)\n",
    "\n",
    "Patches_C = list(itertools.chain.from_iterable(Patches_C))\n",
    "Patches_C=np.asarray(Patches_C)\n",
    "\n",
    "Patches_W = list(itertools.chain.from_iterable(Patches_W))\n",
    "Patches_W=np.asarray(Patches_W)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5382"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16120"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-12-3522cb69f233>, line 56)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-12-3522cb69f233>\"\u001b[0;36m, line \u001b[0;32m56\u001b[0m\n\u001b[0;31m    delta_H3=\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# TRAINING PHASE\n",
    "delta_H4=np.zeros((len(C1), N_branches, S_H4, S_H4))\n",
    "delta_H3=np.zeros((len(C1), N_branches, S_H4, S_H4))\n",
    "from itertools import product\n",
    "###### Chooses patch and defines label #####\n",
    "#for PP in range(0,len(Sequence)):\n",
    "for PP in range(0,1):\n",
    "    SS=Sequence[PP]\n",
    "    if SS<N_F:\n",
    "        Class_label=np.array([1,0,0])\n",
    "        inputPatch=Patches_F[SS]\n",
    "    elif(SS>=N_F) and (SS<(N_F+N_C)):\n",
    "        Class_label=np.array([0,1,0])\n",
    "        inputPatch=Patches_C[SS-N_F]\n",
    "    else:\n",
    "        Class_label=np.array([0,0,1])\n",
    "        inputPatch=Patches_W[SS-N_F-N_C]      \n",
    "    ### Layer 1 ###\n",
    "    H1=[]\n",
    "    H2=[]\n",
    "    H3=np.zeros((len(C1), N_branches, S_H3,S_H3))\n",
    "    H4=np.zeros((len(C1), N_branches, S_H4,S_H4))\n",
    "    x=np.zeros(ClassAmount)\n",
    "    f=np.zeros(ClassAmount)\n",
    "    \n",
    "    \n",
    "    II=1\n",
    "    \n",
    "    for r in range (0, len(C1)):\n",
    "        H1.append(sig.convolve(inputPatch, C1[r], 'valid'))\n",
    "        H2.append(Pool(H1[r], P12))\n",
    "        #From here on BP trakes place!\n",
    "        ITER=0\n",
    "        while II==1: \n",
    "            for b in range(0,N_branches):\n",
    "                H3[r][b]=Sigmoid(sig.convolve(H2[r], C2[r][b],'valid')-H3_bias[r][b])\n",
    "                H4[r][b]=Pool(H3[r][b],P34)       \n",
    "    #Now we have 3x3x4x4 inputs, connected to the 3 output nodes \n",
    "            for k in range(0,ClassAmount):  \n",
    "                x[k]=np.inner(H4.flatten(),W[k].flatten())\n",
    "                f[k]=Sigmoid(x[k]-Output_bias[k])\n",
    "            f=f/np.sum((f))\n",
    "\n",
    "            ###### Back-propagation #####\n",
    "            # First learning the delta's\n",
    "            e_k=f-Class_label\n",
    "            delta_k=e_k*Sigmoid_dx(x)\n",
    "            Output_bias=Output_bias[k]+n_bias*e_k\n",
    "            for k in range(0, ClassAmount):\n",
    "                #update weights output layer\n",
    "                W[k]=W[k]-n_W*delta_k[k]*H4\n",
    "                #determine delta in Sub-sampling layer that is not trained\n",
    "                delta_H4=delta_H4+delta_k[k]*W[k]\n",
    "                #for b in range(0,N_branches):\n",
    "                    #for r in range(0,len(C1):\n",
    "                delta_H3=\n",
    "            ERROR=np.sum((Class_label-f)**2)\n",
    "            ITER=ITER+1\n",
    "            if ERROR<0.55 or ITER>2:\n",
    "                II=0    \n",
    "            \n",
    "n_bias=1*10**-2\n",
    "n_W=1*10**-2\n",
    "n_C2=1*10**-2\n",
    "n_H3_bias=1*10**-2\n",
    "                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5382"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N_F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delta_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Class_label' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-317a5ac2a6af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mClass_label\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'Class_label' is not defined"
     ]
    }
   ],
   "source": [
    "Class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "True\n",
      "True\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n",
      "False\n",
      "True\n",
      "False\n",
      "False\n",
      "False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:6: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-7482657b076a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mN_branches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m             \u001b[0mH3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvolve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mC2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'valid'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mH3_bias\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mH4\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mH3\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP34\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0;31m#Now we have 3x3x4x4 inputs, connected to the 3 output nodes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mClassAmount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "####### Test phase #######\n",
    "Error_Test=[]\n",
    "N_correct=0\n",
    "for PP in range(9000, 10000):\n",
    "    SS=Sequence[PP]\n",
    "    if SS<N_F:\n",
    "        Class_label=np.array([1,0,0])\n",
    "        inputPatch=Patches_F[SS]\n",
    "    elif(SS>=N_F) and (SS<(N_F+N_C)):\n",
    "        Class_label=np.array([0,1,0])\n",
    "        inputPatch=Patches_C[SS-N_F]\n",
    "    else:\n",
    "        Class_label=np.array([0,0,1])\n",
    "        inputPatch=Patches_W[SS-N_F-N_C]\n",
    "    ### Layer 1 ###\n",
    "    H1=[]\n",
    "    H2=[]\n",
    "    H3=np.zeros((len(C1), N_branches, S_H3,S_H3))\n",
    "    H4=np.zeros((len(C1), N_branches, S_H4,S_H4))\n",
    "    x=np.zeros(ClassAmount)\n",
    "    f=np.zeros(ClassAmount)\n",
    "    for r in range (0, len(C1)):\n",
    "        H1.append(sig.convolve(inputPatch, C1[r], 'valid'))\n",
    "        H2.append(Pool(H1[r], P12))\n",
    "        #From here on BP trakes place!\n",
    "        for b in range(0,N_branches):\n",
    "            H3[r][b]=Sigmoid(sig.convolve(H2[r], C2[r][b],'valid')-H3_bias[r][b])\n",
    "            H4[r][b]=Pool(H3[r][b],P34)          \n",
    "    #Now we have 3x3x4x4 inputs, connected to the 3 output nodes \n",
    "    for k in range(0,ClassAmount):  \n",
    "        x[k]=np.inner(H4.flatten(),W[k].flatten())\n",
    "        f[k]=Sigmoid(x[k]-Output_bias[k])\n",
    "    f=f/np.sum((f))\n",
    "    Error_Test.append(np.sum((Class_label-f)**2))\n",
    "            ###### Back-propagation #####\n",
    "            # First learning the delta's\n",
    "    \n",
    "    if np.argmax(f)==np.argmax(Class_label):\n",
    "        print True\n",
    "        N_correct=N_correct+1\n",
    "    else:\n",
    "        print False \n",
    "\n",
    "Perc_corr=float(N_correct)/1000\n",
    "print Perc_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.324"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "float(N_correct)/1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    ###### Back-propagation #####\n",
    "    for k in range(0, ClassAmount):\n",
    "        #bias[k]=bias[k]-n_bias*(Class_label[k]-f[k])\n",
    "        for r in range (0, len(C1)):\n",
    "            for b in range(0,N_branches):\n",
    "                # W[r][b,k]=W[r][b,k]+n_W*(Class_label[k]-f[k])*H4[r][b]\n",
    "                for i, j, u, v, n, m in product(range(0,4), range(0,4), range(0,2), range(0,2), range(0,4), range(0,4)):\n",
    "                    C2[r][b,n,m]=C2[r][b,n,m]+n_C2*(Class_label[k]-f[k])*W[r][b,k,i,j]*H2[r][n+(2*j+u),m+(2*j+v)]\n",
    "                    H3_bias[r][b,2*i+u,2*j+v]=H3_bias[r][b,2*i+u,2*j+v]-n_H3_bias*(Class_label[k]-f[k])*W[r][b,k,i,j]\n",
    "    \n",
    "    print(Class_label,f)\n",
    "    if (PP%100==0):print(PP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"C2.txt\", 'w') as f:\n",
    "    f.write(str(C2))\n",
    "with open(\"W.txt\", 'w') as f:\n",
    "    f.write(str(W))\n",
    "with open(\"H3_bias.txt\", 'w') as f:\n",
    "    f.write(str(H3_bias))\n",
    "with open(\"Bias.txt\", 'w') as f:\n",
    "    f.write(str(bias))\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print Class_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
