{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Le-Net 1 based architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from numpy import linalg as lin\n",
    "import scipy.signal as sig\n",
    "from PIL import Image\n",
    "import glob\n",
    "import matplotlib.cm as cm\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "########### Functions ############################################################################################################################\n",
    "\n",
    "# Define Activitation functions, pooling and convolution functions (the rules)\n",
    "\n",
    "def Sigmoid(x): \n",
    "    return (1/(1+np.exp(-x)))\n",
    "\n",
    "def Sigmoid_dx(x):\n",
    "    return np.exp(-x)/((1+np.exp(-x))**2)\n",
    "\n",
    "def TanH(x):\n",
    "    return (1-np.exp(-x))/(1+np.exp(-x))\n",
    "\n",
    "\n",
    "def Pool(I,W):\n",
    "    PoolImg=np.zeros((len(I)/len(W),len(I)/len(W))) # W must fit an integer times into I.\n",
    "    for i in range(0,len(PoolImg)):\n",
    "        for j in range(0,len(PoolImg)):\n",
    "            SelAr=I[i*len(W):(i+1)*len(W),j*len(W):(j+1)*len(W)]\n",
    "            PoolImg[i,j]=np.inner(SelAr.flatten(),W.flatten()) # Now this is just an inner product since we have vectors\n",
    "    return PoolImg\n",
    "\n",
    "# To automatically make Gaussian kernels\n",
    "def makeGaussian(size, fwhm = 3, center=None):\n",
    "    x = np.arange(0, size, 1, float)\n",
    "    y = x[:,np.newaxis]\n",
    "\n",
    "    if center is None:\n",
    "        x0 = y0 = size // 2\n",
    "    else:\n",
    "        x0 = center[0]\n",
    "        y0 = center[1]\n",
    "\n",
    "    return np.exp(-4*np.log(2) * ((x-x0)**2 + (y-y0)**2) / fwhm**2)\n",
    "\n",
    "# To automatically define pooling nodes\n",
    "def Pool_node(N):\n",
    "    s=(N,N)\n",
    "    a=float(N)*float(N)\n",
    "    return (1.0/a)*np.ones(s) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#################### Define pooling layers ###########################################################################\n",
    "P12=Pool_node(4)*(1.0/100.0) #factor 1000 added to lower values more\n",
    "P34=Pool_node(1)*(1.0/10.0) \n",
    "\n",
    "#################### Define Convolution layers #######################################################################\n",
    "\n",
    "######### First C layer #########\n",
    "C1=[]\n",
    "\n",
    "## First Kernel\n",
    "\n",
    "# Inspiration: http://en.wikipedia.org/wiki/Sobel_operator\n",
    "# http://stackoverflow.com/questions/9567882/sobel-filter-kernel-of-large-size\n",
    "\n",
    "Kernel=np.array([[4,3,2,1,0,-1,-2,-3,-4],\n",
    "                 [5,4,3,2,0,-2,-3,-4,-5], \n",
    "                 [6,5,4,3,0,-3,-4,-5,-6],\n",
    "                 [7,6,5,4,0,-4,-5,-6,-7], \n",
    "                 [8,7,6,5,0,-5,-6,-7,-8],\n",
    "                 [7,6,5,4,0,-4,-5,-6,-7],\n",
    "                 [6,5,4,3,0,-3,-4,-5,-6],\n",
    "                 [5,4,3,2,0,-2,-3,-4,-5],\n",
    "                 [4,3,2,1,0,-1,-2,-3,-4]])\n",
    "\n",
    "C1.append(Kernel)\n",
    "\n",
    "## Second Kernel\n",
    "Kernel=np.matrix.transpose(Kernel)\n",
    "C1.append(Kernel)\n",
    "\n",
    "##Third Kernel\n",
    "#Kernel=makeGaussian(9,5)\n",
    "#Kernel=(1/np.sum(Kernel))*Kernel\n",
    "#C1.append(Kernel)\n",
    "\n",
    "######### Initialize output weights and biases #########\n",
    "\n",
    "# Define the number of branches in one row\n",
    "patchSize=40\n",
    "N_branches= 3\n",
    "ClassAmount=3 # Forest, City, Water\n",
    "Size_C2=5\n",
    "S_H3=((patchSize-C1[0].shape[0]+1)/P12.shape[1])-Size_C2+1\n",
    "S_H4=S_H3/P34.shape[1]\n",
    "\n",
    "\n",
    "\n",
    "import pickle\n",
    "file=open('W.txt','r')\n",
    "W=pickle.load(file)\n",
    "file=open('W2.txt','r')\n",
    "W2=pickle.load(file)\n",
    "file=open('Output_bias.txt','r')\n",
    "Output_bias=pickle.load(file)\n",
    "file=open('H3_bias.txt','r')\n",
    "H3_bias=pickle.load(file)\n",
    "file=open('C2.txt','r')\n",
    "C2=pickle.load(file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# For the extra information regarding the code in the following cell\n",
    "\n",
    "a random patch is chosen in the following way: the program counts how many files and patches there are in total, then it permutes the sequence so that a random patch is chosen every iteration (forest, city, water). After selecting the number the file has to be found back. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# save training parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:6: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "####### Test phase on new images #######\n",
    "Error_Test=[]\n",
    "N_correct=0\n",
    "patchSize=40 \n",
    "\n",
    "Patches_TEST=np.empty([1,patchSize,patchSize])\n",
    "Patches_TEST_RGB=np.empty([1,patchSize,patchSize,3])\n",
    "Patches_t=np.empty([3])\n",
    "\n",
    "name=\"Test/Test4.png\"\n",
    "img = Image.open(name)\n",
    "data=img.convert('RGB')\n",
    "data= np.asarray( data, dtype=\"int32\" )\n",
    "data=0.2126*data[:,:,0]+0.7152*data[:,:,1]+0.0722*data[:,:,2]\n",
    "data2=img.convert('RGB')\n",
    "data2= np.asarray( data2, dtype=\"int32\" )\n",
    "\n",
    "Yamount=data.shape[0]/patchSize # Counts how many times the windowsize fits in the picture\n",
    "Xamount=data.shape[1]/patchSize # Counts how many times the windowsize fits in the picture\n",
    "    \n",
    "    # Create patches for structure\n",
    "data_t=np.array([[data[j*patchSize:(j+1)*patchSize,i*patchSize:(i+1)*patchSize] for i in range(0,Xamount)] for j in range(0,Yamount)])\n",
    "data_t=np.reshape(data_t, [data_t.shape[0]*data_t.shape[1], patchSize, patchSize])\n",
    "Patches_TEST=np.append(Patches_TEST,data_t,axis=0)\n",
    "    #Create patches for colour\n",
    "data_t=np.array([[data2[j*patchSize:(j+1)*patchSize,i*patchSize:(i+1)*patchSize,:] for i in range(0,Xamount)] for j in range(0,Yamount)])\n",
    "data_t=np.reshape(data_t, [data_t.shape[0]*data_t.shape[1], patchSize, patchSize, 3])\n",
    "Patches_TEST_RGB=np.append(Patches_TEST_RGB, data_t,axis=0)\n",
    "Patches_TEST=np.delete(Patches_TEST, 0,0)  \n",
    "Patches_TEST_RGB=np.delete(Patches_TEST_RGB, 0,0) \n",
    "\n",
    "from itertools import product\n",
    "###### Chooses patch and defines label #####\n",
    "#for PP in range(0,len(Sequence)):\n",
    "Forest=0\n",
    "City=0\n",
    "Water=0\n",
    "\n",
    "for PP in range(0,Patches_TEST.shape[0]):\n",
    "    inputPatch=Patches_TEST[PP]\n",
    "    Int_RGB=np.mean(np.mean(Patches_TEST_RGB[PP,:,:,:], axis=0), axis=0)/255\n",
    "    ### Layer 1 ###\n",
    "    H1=[]\n",
    "    H2=[]\n",
    "    H3=np.zeros((len(C1), N_branches, S_H3,S_H3))\n",
    "    H4=np.zeros((len(C1), N_branches, S_H4,S_H4))\n",
    "    x=np.zeros(ClassAmount)\n",
    "    f=np.zeros(ClassAmount)\n",
    "    for r in range (0, len(C1)):\n",
    "        H1.append(sig.convolve(inputPatch, C1[r], 'valid'))\n",
    "        H2.append(Pool(H1[r], P12))\n",
    "        for b in range(0,N_branches):\n",
    "            H3[r][b]=Sigmoid(sig.convolve(H2[r], C2[r][b],'valid')-H3_bias[r][b])\n",
    "            H4[r][b]=Pool(H3[r][b],P34) \n",
    "    y=np.append([H4.flatten()], [Int_RGB])\n",
    "    #Now we have 3x3x4x4 inputs, connected to the 3 output nodes \n",
    "    for k in range(0,ClassAmount):\n",
    "        W_t=np.append([W[k].flatten()], [W2[k]])\n",
    "        x[k]=np.inner(y, W_t)          \n",
    "        f[k]=Sigmoid(x[k]-Output_bias[k])\n",
    "    f=f/np.sum((f))\n",
    "    if np.argmax(f)==0:\n",
    "        \n",
    "    if np.argmax(f)==1:\n",
    "        City=City+1\n",
    "    if np.argmax(f)==2:\n",
    "        Water=Water+1\n",
    "\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "321 104 4\n"
     ]
    }
   ],
   "source": [
    "print Forest, City, Water"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.38482108,  0.41534804,  0.35988971])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Int_RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
